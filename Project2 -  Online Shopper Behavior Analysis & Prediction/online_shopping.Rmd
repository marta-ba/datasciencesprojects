---
title: "online shopping model"
author: "Marta Blanco"
date: "2024-12-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# INTENCIÓN DE COMPRA DE COMPRADORES EN LÍNEA
## El conjunto de datos que se proporciona consta de vectores de características que pertenecen a 12.330 sesiones y se construyó de tal manera que cada sesión pertenecía a un usuario diferente en un período de 1 año, con objeto de evitar cualquier tendencia a una campaña específica, día especial, perfil de usuario o período. De las 12.330 sesiones, el 84.5% (10.422) fueron muestras de clase negativas que no terminaron con compras, y el resto (1.908) fueron muestras de clases positivas que terminaron con compras. El conjunto de datos consta de 10 atributos numéricos y 8 categóricos. El atributo ‘Ingresos’ se puede usar como etiqueta de clase. El objetivo general de esta prueba de evaluación consiste en analizar el comportamiento del comprador en línea en tiempo real. Para ello, se testarán diferentes métodos y algoritmos y se deberá seleccionar aquel o aquellos métodos que sean más óptimos de cara a predecir la intención de compra del visitante

```{r}
library(DataExplorer)
library(knitr)
library(kableExtra)
library(magrittr)
library(tidyverse)
library(caret)
library(dlookr)
library(naniar)
library(rpart)
library(randomForest)
library(gbm)
library(corrplot)
library(ggplot2)
library(ggplot2)
library(doParallel)
library(GGally)
```
```{r}
setwd("C://Users//marta//Desktop//portfolio//project3 online shopping behaviur")
datos <-read.csv("2020_online_shoppers_intention.csv", header = T, sep=",", dec = ".")
head(datos)
```
# EDA

```{r}
datos_orig<-datos
summary(datos)
```
Tras el sumario observamos que la en variable de estudio Revenue existe una gran diferencia en cuanto al numero de observaciones de individuos que compran y que no compran, esto es un indicativo de que la muestra está desbalanceada, lo que implica que deberemos balancerla antes de realizar el estudio .

Existen variables numéricas que convertiremos a factor, asi como por ejemplo la variable Revenue y weekend del tipo logica, las convertiremos tambien a factor
```{r}
datos$Weekend<-as.numeric(datos$Weekend)
datos$Revenue<-as.numeric(datos$Revenue)
datos$Weekend<-ifelse(datos$Weekend =='0','no','yes')
datos$Revenue<-ifelse(datos$Revenue =='0', 'no', 'yes')
datos$Weekend<-as.factor(datos$Weekend)
datos$Revenue<-as.factor(datos$Revenue)
levels(datos$Revenue)


```


```{r}
#Convierto a factor variables numéricas:
#specialDay consideramos 0: lejano a festivo 1: proximo a festivo
datos$SpecialDay<-ifelse(datos$SpecialDay == 0 , 1, 0)
datos$SpecialDay<-as.factor(datos$SpecialDay)

datos$OperatingSystems <-as.factor(datos$OperatingSystems)     
datos$Browser<-as.factor(datos$Browser)    
datos$Region<-as.factor(datos$Region)       
datos$TrafficType<-as.factor(datos$TrafficType)       
datos$VisitorType<-as.factor(datos$VisitorType)
```

```{r}


plot_intro(datos)
```
## graficamos variable respuesta

```{r}
ggplot(data = datos, aes(x = Revenue, y = ..count.., fill = Revenue)) +
  geom_bar() +
  scale_fill_manual(values = c("gray50", "orangered2")) +
  labs(title = "Ingresos") +
  theme_bw() +
  theme(legend.position = "bottom")
```

```{r}
#Month
ggplot(data = datos, aes(x = Month, y = ..count.., fill = Revenue)) +
  geom_bar() +
  scale_fill_manual(values = c("gray50", "orangered2")) +
  labs(title = "Month") +
  theme_bw() +
  theme(legend.position = "bottom")
```
```{r}
#Operating systems
ggplot(data = datos, aes(x = OperatingSystems, y = ..count.., fill = Revenue)) +
  geom_bar() +
  scale_fill_manual(values = c("gray50", "orangered2")) +
  labs(title = "Operating Systems") +
  theme_bw() +
  theme(legend.position = "bottom")
```

```{r}
#MSpecial Day
ggplot(data = datos, aes(x = SpecialDay, y = ..count.., fill = Revenue)) +
  geom_bar() +
  scale_fill_manual(values = c("gray50", "orangered2")) +
  labs(title = "special Day") +
  theme_bw() +
  theme(legend.position = "bottom")
```

```{r}
#distribucion de frecuencias para variables continuas
plot_histogram(datos)
```

```{r}

ggcorr(datos[,1:9],geom="circle",method = c("pairwise", "pearson"),low = "darkred", mid = "white", high = "darkgreen")

```
```{r}
correl <- cor(datos[,1:9])
correl
```

```{r}
library(corrplot)
corrplot(correl,method= 'number')
```
# Selección de variables

Para seleccionar las características vamos en primer lugar a eliminar aquellas variables que tengan una correlacion alta. Establecemos el punto de corte en un 85%, y las eliminamos de nuestro dataset.


    
```{r}
#Variables muy correlacionadas; 
set.seed(7)
cutoff <- 0.85
correlations <- cor(datos[,1:9])
highlyCorrelated <- findCorrelation(correlations, cutoff=cutoff)
for (value in highlyCorrelated) {
  #mostramos las variables con alta correlacion
    print(names(datos)[value])
}
```
```{r}
datos_sin_altas<- datos[,-highlyCorrelated]
dim(datos_sin_altas)
```

```{r}
#varianza cero
varzero_datos <-datos%>% nearZeroVar(saveMetrics = TRUE)
varzero_datos
```
En este caso, no obtenemos ninuna variable con varianza cercana a cero.

## Escalado y Centrado de la Base de datos

### Realizamos el escalado y centrado de datos.
```{r}
#Escalado y Centrado de Datos Para evitar la influencia de los valores altos en determinadas variables, ya que no están todas en el mismo rango, debemos reescalarlos y centrarlos en media 0.
valores_normalizar <- preProcess(datos_sin_altas, method = c("center", "scale"))

datos_normal <- predict(valores_normalizar, datos_sin_altas)

summary(datos_normal)
```

## Equilibrado de la muestra

### Como habíamos identificado previamente, la base está desbalanceada, existiendo mas casos de visitantes que no compran, realizamos el balanceado de la base, con la funcion SMOOTE de caret.

```{r}


# Sobremuestreo
datos_reducidos <- upSample(x = datos_normal[, -which(names(datos_normal) == "Revenue")], 
                            y = datos_normal$Revenue)

# Verificar el balance
table(datos_reducidos$Class)



```
##Funciones para la evaluacion y representacion de modelos:

Función que extrae los resultados derivados de cada modelo

```{r}
Resul_Modelo <- function( modelo ){

# Cálculos
  # Curvas ROC
  pred_prob_ent <- predict(modelo, entrenamiento, type="prob")
  pred_prob_val <- predict(modelo, validacion, type="prob")
  curvaROC_ent <- roc(entrenamiento$Revenue,pred_prob_ent[,"yes"])
  curvaROC_val <- roc(validacion$Revenue,pred_prob_val[,"yes"])
  # Predicciones del modelo
  pred_Y <- predict(modelo, validacion, type="raw")

# Resultados generales
  print(modelo$results)
  print(paste("Mejor modelo:"))
  print(modelo$bestTune)
  print(modelo$finalModel)
  print(paste(c("ROC del modelo con el fichero de validación:"), auc(curvaROC_val)))

# Gráfico de curvas ROC
  if (modelo$method == "treebag" | modelo$method == "xxx"){
    plot(curvaROC_val,col="red", main="Simulación con la curva ROC del modelo")
    legend("bottomright", legend = c("Validacion"), col = c("red"), lwd = 2)
  }else{
    plot(curvaROC_ent,col="blue", main="Simulación con la curva ROC del modelo")
    plot(curvaROC_val, col="red", add=TRUE)
    legend("bottomright", legend = c("Entrenamiento", "Validacion"), col = c("blue", "red"), lwd = 2)
  }

# Tabla de confusión e importancia de las variables
  print(confusionMatrix(modelo))
  print(CrossTable(pred_Y, validacion$Revenue, prop.chisq = TRUE, prop.c = TRUE, prop.r = TRUE))
  print(varImp(modelo))
}
```



## FUNCION QUE AGREGA CURVAS ROC
```{r}
CurvasROC <- function( modelos ){
  n_modelos = length(modelos)
  pred <- NULL
  nombresModelos <- NULL
  colores <- NULL
  
  pred[[1]] <- predict(modelos[1], validacion, type="prob")

  # Colores para cada modelo generados de forma aleatoria
  colores <- colours(sample(1:502, size = n_modelos))

  plot ( roc(validacion$Revenue,pred[[1]][[1]][,"yes"]), col = colores[1], main="Curvas ROC de todos los modelos" )

  for( j in 1:length(modelos))
  {
    nombresModelos[j] <- modelos[[j]]$method
  }
  
  legend("bottomright", legend = nombresModelos, col = colores, lwd = 2)
         
  for (i in 2:n_modelos){
    pred[[i]] <- predict(modelos[i], validacion, type="prob")
    plot ( roc(validacion$Revenue,pred[[i]][[1]][,"yes"]), col = colores[i], add=TRUE )
  }
}
```

## Tabla comparativa de modelos
```{r}
Result <- function ( modelos ){
  n_modelos = length(modelos)
  comparativa <- matrix(0, n_modelos, 7)
  pred <- NULL

  for (i in 1:n_modelos){
    pred[[i]] <- predict(modelos[i], validacion, type="prob")
    comparativa[i,1] = modelos[[i]]$method

       comparativa[i,2] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("ROC")]
       comparativa[i,3] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Sens")]
       comparativa[i,4] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Spec")]
       comparativa[i,5] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Accuracy")]
       comparativa[i,6] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Kappa")]
    
    comparativa[i,7] = auc(roc(validacion$Revenue,pred[[i]][[1]][,"yes"]))
  }
  colnames(comparativa) <- c("Modelo", "ROC", "Sens", "Spec", "Accuracy", "Kappa", "ROC Validación")
  return(comparativa)
}
```

## Muestras de entrenamiento y validación

Creamos muestras de entrenamiento y validación para la ejecucion de nuestros modelos. Creamos nuestras particiones en una proporcion 80-20 (entrenamiento-validacion respectivamente)

```{r}
# Semilla para reproducibilidad
set.seed(107)

# Crear índice de partición (80% entrenamiento, 20% validación)
Indice_Particion <- createDataPartition(datos_reducidos$Revenue, p = 0.80, list = FALSE)

# Dividir los datos
entrenamiento <- datos_reducidos[Indice_Particion, ]
validacion <- datos_reducidos[-Indice_Particion, ]

# Verificar las dimensiones de los conjuntos
dim(entrenamiento)  # Ver filas y columnas del conjunto de entrenamiento
dim(validacion)     # Ver filas y columnas del conjunto de validación

# Verificar balance en los conjuntos
table(entrenamiento$Revenue)
table(validacion$Revenue)

```
```{r}
table(datos_reducidos$Revenue)

```

```{r}
dim(datos_reducidos)

```
```{r}
install.packages("UBL") # Instala el paquete
library(UBL)            # Carga el paquete

```


```{r}
library(DMwR2)

# Asegúrate de usar "balance" para equilibrar las clases
datos_reducidos <- SmoteClassif(Revenue ~ ., datos_normal, C.perc = "balance")

# Verifica el balance
table(datos_reducidos$Revenue)
```

